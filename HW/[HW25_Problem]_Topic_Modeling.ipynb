{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "[HW25_Problem] Topic Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUEqzkNmnyYH"
      },
      "source": [
        "# [HW2] Topic Modeling\n",
        "1. Crawling News\n",
        "2. Preprocessing\n",
        "3. Build Term-Document Matrix\n",
        "4. Topic modeling\n",
        "5. Visualization\n",
        "\n",
        "```\n",
        "ğŸ”¥ ì´ë²ˆ ì‹œê°„ì—ëŠ” Topic Modelingë¥¼ ì§ì ‘ í¬ë¡¤ë§í•œ ë‰´ìŠ¤ ë°ì´í„°ì— ëŒ€í•´ì„œ ìˆ˜í–‰í•´ë³´ëŠ” ì‹œê°„ì„ ê°–ê² ìŠµë‹ˆë‹¤. \n",
        "\n",
        "ë¨¼ì € ë„¤ì´ë²„ì—ì„œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê°„ë‹¨í•˜ê²Œ í¬ë¡¤ë§í•©ë‹ˆë‹¤.\n",
        "ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ ì´í›„ Term-document Matrixë¥¼ ë§Œë“¤ê³  ì´ë¥¼ non-negative factorizationì„ ì´ìš©í•´ í–‰ë ¬ ë¶„í•´ë¥¼ í•˜ì—¬ Topic modelingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "t-distributed stochastic neighbor embedding(T-SNE) ê¸°ë²•ì„ ì´ìš©í•´ Topicë³„ ì‹œê°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIARcrg_oNMN"
      },
      "source": [
        "!pip install newspaper3k\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPu9TCFEoK_m"
      },
      "source": [
        "# í¬ë¡¤ë§ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "from bs4 import BeautifulSoup\n",
        "from newspaper import Article\n",
        "from time import sleep\n",
        "from time import time\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from datetime import datetime\n",
        "from multiprocessing import Pool\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU2ipk6ZvZXf"
      },
      "source": [
        "```\n",
        "ğŸ’¡ Crawling(í¬ë¡¤ë§)ì´ë€?\n",
        "\n",
        "í¬ë¡¤ë§ì€ ì›¹ í˜ì´ì§€ì—ì„œ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ë‚´ëŠ” ì‘ì—…ì„ ë§í•©ë‹ˆë‹¤.\n",
        "ì´ë²ˆ ì‹œê°„ì—ëŠ” ì •ì  í˜ì´ì§€ì¸ ë„¤ì´ë²„ì˜ ë‰´ìŠ¤ ì‹ ë¬¸ ê¸°ì‚¬ ì›¹í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.\n",
        "\n",
        "HTMLì€ ì„¤ëª…ë˜ì–´ ìˆëŠ” ìë£Œê°€ ë§ê¸° ë•Œë¬¸ì— ìƒëµí•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "HTML êµ¬ì¡° íŒŒì•… ë° íƒœê·¸ì— ëŒ€í•œ ì„¤ëª…ì€ ì•„ë˜ ì°¸ê³ ìë£Œë¥¼ ì‚´í´ë´ì£¼ì„¸ìš” !\n",
        "```\n",
        "\n",
        "ì°¸ê³ : [ìœ„í‚¤í”¼ë””ì•„: ì •ì í˜ì´ì§€](https://ko.wikipedia.org/wiki/%EC%A0%95%EC%A0%81_%EC%9B%B9_%ED%8E%98%EC%9D%B4%EC%A7%80)\n",
        "\n",
        "ì°¸ê³ : [ìƒí™œì½”ë”©: HTML](https://opentutorials.org/course/2039)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0UYQWmsnHTF"
      },
      "source": [
        "def crawl_news(query: str=None, crawl_num: int=1000, workers: int=4):\n",
        "    '''ë‰´ìŠ¤ ê¸°ì‚¬ í…ìŠ¤íŠ¸ê°€ ë‹´ê¸´ listë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "    Keyword arguments:\n",
        "    query -- ê²€ìƒ‰ì–´ (default None)\n",
        "    crawl_num -- ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°œìˆ˜ (defualt 1000)\n",
        "    workers -- multi-processingì‹œ ì‚¬ìš©í•  threadì˜ ê°œìˆ˜ (default 4)\n",
        "    '''\n",
        "\n",
        "    url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'\n",
        "    articleList = []\n",
        "    crawled_url = set()\n",
        "    keyboard_interrupt = False\n",
        "    t = time()\n",
        "    idx = 0\n",
        "    page = 1\n",
        "\n",
        "    \n",
        "    # ì„œë²„ì— url ìš”ì²­ì˜ ê²°ê³¼ë¥¼ ì„ ì–¸\n",
        "    res = requests.get(url.format(query))\n",
        "    sleep(0.5)\n",
        "    # resë¥¼ parsingí•  parserë¥¼ ì„ ì–¸\n",
        "    bs = BeautifulSoup(res.text, 'html.parser')\n",
        "    \n",
        "    with Pool(workers) as p:\n",
        "        while idx < crawl_num:            \n",
        "            table = bs.find('ul', {'class': 'list_news'})\n",
        "            li_list = table.find_all('li', {'id': re.compile('sp_nws.*')})\n",
        "            area_list = [li.find('div', {'class':'news_area'}) for li in li_list]\n",
        "            a_list = [area.find('a', {'class':'news_tit'}) for area in area_list]\n",
        "            \n",
        "            for n in a_list[:min(len(a_list), crawl_num-idx)]:\n",
        "                articleList.append(n.get('title'))\n",
        "                idx += 1\n",
        "            page += 1\n",
        "\n",
        "            pages = bs.find('div', {'class': 'sc_page_inner'})\n",
        "            next_page_url = [p for p in pages.find_all('a') if p.text == str(page)][0].get('href')\n",
        "\n",
        "            req = requests.get('https://search.naver.com/search.naver' + next_page_url)\n",
        "            bs = BeautifulSoup(req.text, 'html.parser')\n",
        "    return articleList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ln1Wih0XVnt"
      },
      "source": [
        "```\n",
        "ğŸ”¥ ì´ì œ 'êµ¬ê¸€'ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë‰´ìŠ¤ ê¸°ì‚¬ 1000ê°œì˜ ì œëª©ì„ í¬ë¡¤ë§í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6CAFa6J56yJ"
      },
      "source": [
        "query = 'êµ¬ê¸€'\n",
        "\n",
        "articleList = crawl_news(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDIS5V1yAcRT"
      },
      "source": [
        "articleList[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9HG4LxOaa1r"
      },
      "source": [
        "```\n",
        "ğŸ”¥ íƒœê±°(tagger)ë¥¼ ì´ìš©í•´ í•œê¸€ ëª…ì‚¬ì™€ ì•ŒíŒŒë²³ë§Œì„ ì¶”ì¶œí•´ì„œ term-document matrix (tdm)ì„ ë§Œë“¤ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "íƒœê±°(tagger)ëŠ” tokenizationì—ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ë‹¤ë£¨ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "```\n",
        "\n",
        "ì°¸ê³ : [konlpy: morph analyzer](https://konlpy-ko.readthedocs.io/ko/v0.4.3/morph/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-15T06:17:04.018304Z",
          "start_time": "2019-05-15T06:09:10.729214Z"
        },
        "id": "Mdr-aTytaCLr"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-29T08:48:53.790086Z",
          "start_time": "2019-05-29T08:46:38.984818Z"
        },
        "id": "HUN9k5DXaCLs"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "# Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ì„ ì–¸\n",
        "t = Okt()\n",
        "\n",
        "words_list_ = []\n",
        "vocab = Counter()\n",
        "tag_set = set(['Noun', 'Alpha'])\n",
        "stopwords = set(['ê¸€ì'])\n",
        "\n",
        "for i, article in enumerate(articleList):\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "    \n",
        "    # taggerë¥¼ ì´ìš©í•œ í’ˆì‚¬ íƒœê¹…\n",
        "    words = t.pos(article, norm=True, stem=True)\n",
        "\n",
        "    ############################ ANSWER HERE ################################\n",
        "    # TODO: ë‹¤ìŒì˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‹¨ì–´ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì™„ì„±í•˜ì„¸ìš”.\n",
        "    # ì¡°ê±´ 1: ëª…ì‚¬ì™€ ì•ŒíŒŒë²³ tagë¥¼ ê°€ì§„ ë‹¨ì–´\n",
        "    # ì¡°ê±´ 2: ì² ì ê¸¸ì´ê°€ 2ì´ìƒì¸ ë‹¨ì–´ \n",
        "    # ì¡°ê±´ 3: stopwordsì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ë‹¨ì–´\n",
        "    #########################################################################        \n",
        "\n",
        "    vocab.update(words)\n",
        "    words_list_.append((words, article))\n",
        "    \n",
        "vocab = sorted([w for w, freq in vocab.most_common(10000)])\n",
        "word2id = {w: i for i, w in enumerate(vocab)}\n",
        "words_list = []\n",
        "for words, article in words_list_:\n",
        "    words = [w for w in words if w in word2id]\n",
        "    if len(words) > 10:\n",
        "        words_list.append((words, article))\n",
        "        \n",
        "del words_list_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L1BkQeaaCLv"
      },
      "source": [
        "## Build document-term matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5YfokxJf86R"
      },
      "source": [
        "```\n",
        "ğŸ”¥ ì´ì œ document-term matrixë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "document-term matrixëŠ” (ë¬¸ì„œ ê°œìˆ˜ x ë‹¨ì–´ ê°œìˆ˜)ì˜ Matrixì…ë‹ˆë‹¤.\n",
        "```\n",
        "\n",
        "ì°¸ê³ : [Document-Term Matrix](https://wikidocs.net/24559)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-29T08:48:56.005889Z",
          "start_time": "2019-05-29T08:48:53.792571Z"
        },
        "id": "MI5weWREaCLv"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import numpy as np\n",
        "\n",
        "dtm = np.zeros((len(words_list), len(vocab)), dtype=np.float32)\n",
        "for i, (words, article) in enumerate(words_list):\n",
        "    for word in words:\n",
        "        dtm[i, word2id[word]] += 1\n",
        "        \n",
        "dtm = TfidfTransformer().fit_transform(dtm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0xYqpVtmgoL"
      },
      "source": [
        "```\n",
        "ğŸ”¥ document-term matrixë¥¼ non-negative factorization(NMF)ì„ ì´ìš©í•´ í–‰ë ¬ ë¶„í•´ë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ğŸ’¡ Non-negative Factorizationì´ë€?\n",
        "\n",
        "NMFëŠ” ì£¼ì–´ì§„ í–‰ë ¬ non-negative matrix Xë¥¼ non-negative matrix Wì™€ Hë¡œ í–‰ë ¬ ë¶„í•´í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.\n",
        "ì´ì–´ì§€ëŠ” ì½”ë“œë¥¼ í†µí•´ Wì™€ Hì˜ ì˜ë¯¸ì— ëŒ€í•´ íŒŒì•…í•´ë´…ì‹œë‹¤.\n",
        "```\n",
        "ì°¸ê³ : [Non-negative Matrix Factorization](https://angeloyeo.github.io/2020/10/15/NMF.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRWNuIguaCLy"
      },
      "source": [
        "## Topic modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erhwS2ntQBSD"
      },
      "source": [
        "# Non-negative Matrix Factorization\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "K=5\n",
        "nmf = NMF(n_components=K, alpha=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I24Y78G3VvO"
      },
      "source": [
        "```\n",
        "ğŸ”¥ sklearnì˜ NMFë¥¼ ì´ìš©í•´ Wì™€ H matrixë¥¼ êµ¬í•´ë´…ì‹œë‹¤.\n",
        "WëŠ” document length x K, HëŠ” K x term lengthì˜ ì°¨ì›ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "Wì˜ í•˜ë‚˜ì˜ rowëŠ” ê°ê°ì˜ featureì— ì–¼ë§Œí¼ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¤„ ì§€ì— ëŒ€í•œ weightì…ë‹ˆë‹¤.\n",
        "Hì˜ í•˜ë‚˜ì˜ rowëŠ” í•˜ë‚˜ì˜ featureë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
        "\n",
        "ìš°ì„  í•˜ë‚˜ì˜ Topic (Hì˜ në²ˆì§¸ row)ì— ì ‘ê·¼í•´ì„œ í•´ë‹¹ topicì— ëŒ€í•´ ê°’ì´ ê°€ì¥ ë†’ì€ 20ê°œì˜ ë‹¨ì–´ë¥¼ ì¶œë ¥í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2TY6gu4QH1o"
      },
      "source": [
        "W = nmf.fit_transform(dtm)\n",
        "H = nmf.components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbNWlTAv5Zn2"
      },
      "source": [
        "```\n",
        "ğŸ”¥ ìš°ì„  í•˜ë‚˜ì˜ Topic (Hì˜ në²ˆì§¸ row)ì— ì ‘ê·¼í•´ì„œ í•´ë‹¹ topicì— ëŒ€í•´ ê°’ì´ ê°€ì¥ ë†’ì€ 20ê°œì˜ ë‹¨ì–´ë¥¼ ì¶œë ¥í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-29T08:48:58.523062Z",
          "start_time": "2019-05-29T08:48:58.500171Z"
        },
        "id": "uSzB5PBuaCL2"
      },
      "source": [
        "for k in range(K):\n",
        "    print(f\"{k}th topic\")\n",
        "    for index in H[k].argsort()[::-1][:20]:\n",
        "        print(vocab[index], end=' ')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTP6lUft5C4j"
      },
      "source": [
        "```\n",
        "ğŸ”¥ ì´ë²ˆì—ëŠ” Wì—ì„œ í•˜ë‚˜ì˜ Topic (Wì˜ në²ˆì§¸ column)ì— ì ‘ê·¼í•´ì„œ í•´ë‹¹ topicì— ëŒ€í•´ ê°’ì´ ê°€ì¥ ë†’ì€ 3ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©ì„ ì¶œë ¥í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-29T08:48:58.553639Z",
          "start_time": "2019-05-29T08:48:58.525169Z"
        },
        "scrolled": false,
        "id": "K1CniIn7aCL5"
      },
      "source": [
        "for k in range(K):\n",
        "    print(f\"==={k}th topic===\")\n",
        "    for index in W[:, k].argsort()[::-1][:3]:\n",
        "        print(words_list[index][1])\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOplJlO5tFi"
      },
      "source": [
        "```\n",
        "â“ 2ë²ˆì§¸ í† í”½ì— ëŒ€í•´ ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°–ëŠ” ì œëª© 5ê°œë¥¼ ì¶œë ¥í•´ë³¼ê¹Œìš”?\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-29T08:48:58.574010Z",
          "start_time": "2019-05-29T08:48:58.567122Z"
        },
        "id": "Jfm4fK4jaCL9"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7AZ3SyS6Y5L"
      },
      "source": [
        "```\n",
        "ğŸ”¥ ì´ë²ˆì—ëŠ” t-SNEë¥¼ ì´ìš©í•´ Topicë³„ ì‹œê°í™”ë¥¼ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ğŸ’¡ t-SNEëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
        "\n",
        "t-Stochastic Neighbor Embedding(t-SNE)ì€ ê³ ì°¨ì›ì˜ ë²¡í„°ë¥¼ \n",
        "ì €ì°¨ì›(2~3ì°¨ì›) ë²¡í„°ë¡œ ë°ì´í„°ê°„ êµ¬ì¡°ì  íŠ¹ì§•ì„ ìœ ì§€í•˜ë©° ì¶•ì†Œë¥¼ í•˜ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì£¼ë¡œ ê³ ì°¨ì› ë°ì´í„°ì˜ ì‹œê°í™”ë¥¼ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "```\n",
        "\n",
        "ì°¸ê³ : [lovit: t-SNE](https://lovit.github.io/nlp/representation/2018/09/28/tsne/#:~:text=t%2DSNE%20%EB%8A%94%20%EA%B3%A0%EC%B0%A8%EC%9B%90%EC%9D%98,%EC%9D%98%20%EC%A7%80%EB%8F%84%EB%A1%9C%20%ED%91%9C%ED%98%84%ED%95%A9%EB%8B%88%EB%8B%A4.)\n",
        "\n",
        "ì°¸ê³ : [ratsgo: t-SNE](https://ratsgo.github.io/machine%20learning/2017/04/28/tSNE/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1HlyoakaCMA"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-29T08:49:22.529080Z",
          "start_time": "2019-05-29T08:48:58.612549Z"
        },
        "id": "rqajA3lDaCMB"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# n_components = ì°¨ì› ìˆ˜\n",
        "tsne = TSNE(n_components=2, init='pca', verbose=1)\n",
        "\n",
        "# W matrixì— ëŒ€í•´ t-sneë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "W2d = tsne.fit_transform(W)\n",
        "\n",
        "# ê° ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©ë§ˆë‹¤ ê°€ì¤‘ì¹˜ê°€ ê°€ì¥ ë†’ì€ topicì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "topicIndex = [v.argmax() for v in W]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-16T08:24:10.840813Z",
          "start_time": "2019-05-16T08:24:10.695706Z"
        },
        "scrolled": true,
        "id": "pc76X-jSaCME"
      },
      "source": [
        "from bokeh.models import HoverTool\n",
        "from bokeh.palettes import Category20\n",
        "from bokeh.io import show, output_notebook\n",
        "from bokeh.plotting import figure, ColumnDataSource\n",
        "output_notebook()\n",
        "\n",
        "# ì‚¬ìš©í•  íˆ´ë“¤\n",
        "tools_to_show = 'hover,box_zoom,pan,save,reset,wheel_zoom'\n",
        "p = figure(plot_width=720, plot_height=580, tools=tools_to_show)\n",
        "\n",
        "source = ColumnDataSource(data={\n",
        "    'x': W2d[:, 0],\n",
        "    'y': W2d[:, 1],\n",
        "    'id': [i for i in range(W.shape[0])],\n",
        "    'document': [article for words, article in words_list],\n",
        "    'topic': [str(i) for i in topicIndex],  # í† í”½ ë²ˆí˜¸\n",
        "    'color': [Category20[K][i] for i in topicIndex]\n",
        "})\n",
        "p.circle(\n",
        "    'x', 'y',\n",
        "    source=source,\n",
        "    legend='topic',\n",
        "    color='color'\n",
        ")\n",
        "\n",
        "# interaction\n",
        "p.legend.location = \"top_left\"\n",
        "hover = p.select({'type': HoverTool})\n",
        "hover.tooltips = [(\"Topic\", \"@topic\"), ('id', '@id'), (\"Article\", \"@document\")]\n",
        "hover.mode = 'mouse'\n",
        "\n",
        "show(p)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}