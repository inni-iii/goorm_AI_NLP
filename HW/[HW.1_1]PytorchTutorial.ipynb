{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[HW1.1]PytorchTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **[HW1.1] PyTorch Tutorial**\n",
        "1. Install packages\n",
        "2. Tensor\n",
        "3. AutoGrad\n",
        "\n",
        "딥러닝 실습은, 수업시간에 배웠던 개념들을 직접 코드로 옮겨보며 이를 폭넓게 이해하는 데에 초점을 맞추고 있습니다. 실습에서 사용한 예시 외에도, 다양한 architecture를 직접 구성해보며 각 node와 function의 역할을 명확히 이해해보시길 바랍니다.\n",
        "\n",
        "이번 실습에서는 딥러닝 모델을 만들때 사용하는 PyTorch library에 대한 기본 개념들을 익혀보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4iquuOQj1g9"
      },
      "source": [
        "# 1. Import packages\n",
        "\n",
        "> 필요한 package를 설치하고 import합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvlE_XOWS33"
      },
      "source": [
        "런타임의 유형을 변경해줍니다.\n",
        "\n",
        "상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n",
        "\n",
        "변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqVdEuPQzMAH",
        "outputId": "45548956-31fe-4d0a-a79b-47ac481aee89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "# 2. Tensor operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxQqLw-Dl_Zw"
      },
      "source": [
        "텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타냅니다.\n",
        "\n",
        "GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, 텐서는 NumPy의 ndarray와 매우 유사합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8XqtZa8sXsw"
      },
      "source": [
        "##텐서 초기화하기\n",
        "\n",
        "데이터로부터 직접 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnmrA9ltYs0",
        "outputId": "78537d2f-2c01-4d0b-8567-a7ee9137c263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x = torch.tensor(data)\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZx51U6fUXSc"
      },
      "source": [
        "Numpy array로부터 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5m4qus2UnoL",
        "outputId": "f1fe9dbe-76f4-44fe-bd80-cb8f9084c3fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np_array = np.array(data)\n",
        "x = torch.from_numpy(np_array)\n",
        "x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BfwipaTYEFI"
      },
      "source": [
        "Tensor에서 Numpy array로 변환하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkEJ9mBMCOd",
        "outputId": "b66498b6-8d44-467a-94c6-7e43a481d42d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.numpy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZ-A5rxYOSx"
      },
      "source": [
        "다른 텐서와 같은 모양의 텐서 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkJRGOaEyyc0",
        "outputId": "00ddbe0f-2c6c-4ee3-ec44-e2e77ad96916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_ones = torch.ones_like(x) # x_data의 속성을 유지합니다.\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.9515, 0.9015],\n",
            "        [0.9265, 0.6333]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1E5bEPHZskg"
      },
      "source": [
        "주어진 shape으로 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk1OASeazKtN",
        "outputId": "870df9a2-2207-45e3-f8b3-330f36520dc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "shape = (3,4)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.0094, 0.4437, 0.6032, 0.8980],\n",
            "        [0.9419, 0.9328, 0.3431, 0.5875],\n",
            "        [0.4361, 0.7791, 0.6991, 0.5087]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## 텐서의 속성\n",
        "\n",
        "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWWRcNjaLDi",
        "outputId": "b00d028f-0ef2-4fd1-c06b-abd7bbe479f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7LymV5aYEA"
      },
      "source": [
        "아래와 같이 cpu에 할당되어 있는 tensor를 gpu에 옮길 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKvYqt3ZaOXZ",
        "outputId": "df9ff2d9-05f7-4b58-f9a1-d3085249ee3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device('cuda')\n",
        "tensor = tensor.to(device)\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01vssH7n24cq"
      },
      "source": [
        "## 텐서 연산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqON2YtYczmS"
      },
      "source": [
        "Numpy식의 인덱싱과 슬라이싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOv_w4LhjTDq",
        "outputId": "717ea6be-df59-45cc-f446-c21b8edd2fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor = torch.ones(3, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0J9p1WkpHO"
      },
      "source": [
        "텐서 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68HmhqlknkX",
        "outputId": "a2f50f5c-1bf5-47ff-df8e-1c24b0ec789a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
        "print(t1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYxrFYAjbQuS",
        "outputId": "d0b354a0-e2c8-4b92-93f9-2833cca7f065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThLzN1ONbV-p"
      },
      "source": [
        "텐서 곱하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCMMXj8ejXVG",
        "outputId": "13b0237a-4bcf-4a6c-97e9-0895c4bfb783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 요소별 곱(element-wise product)을 계산합니다\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "\n",
        "# 다른 문법:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9752P1u90enu"
      },
      "source": [
        "텐서간 matrix multiplication 진행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhOPv757T4NG",
        "outputId": "e881246e-dec6-43e5-a653-35fd4aed69cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# 다른 문법:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC_i0POOIf0M"
      },
      "source": [
        "# 3. AUTOGRAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tQLTW4vcRJK"
      },
      "source": [
        "PyTorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있습니다. \n",
        "이는 모든 node에 대한 미분 값을 자동으로 계산해주게 됩니다.\n",
        "\n",
        "입력 X, 파라미터 W , 그리고 cross-entropy loss를 사용하는 logistic regression model의 gradient를 autograd를 이용해서 구해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3w8_NGdCL1"
      },
      "source": [
        "## 입력 및 파라미터 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52zAKX7zLl7n",
        "outputId": "b0d5b47f-ed93-4f4b-a46e-148ae2a14a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "print(y)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([0., 0., 0.])\n",
            "tensor([[-1.3070,  0.7311,  0.1521],\n",
            "        [-0.0277,  2.5812, -1.4412],\n",
            "        [-0.8154,  1.0854,  0.6479],\n",
            "        [ 0.0567, -1.3940, -1.4052],\n",
            "        [-1.8552, -1.3708,  0.9981]], requires_grad=True)\n",
            "tensor([ 0.9278, -0.3298, -0.1309], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfSzTTVUeb06"
      },
      "source": [
        "## Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09v6hrSIecG-",
        "outputId": "984aaf4b-2c38-44c2-ec64-f4db9920f8b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = torch.matmul(x,w)+b\n",
        "z"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.0208,  1.3031, -1.1792], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R19jHY9Pemt"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "PyTorch에서는 node를 크게 2가지의 방법의 api를 활용해서 사용합니다.\n",
        "\n",
        "1. [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "2. [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)\n",
        "\n",
        "torch.nn은 사전에 node를 초기화 시켜놓고, 해당 node에 텐서를 통과시켜 값을 받는 형태인 반면, torch.nn.functional은 사전에 초기화없이 바로 함수처럼 사용하는 방식입니다.\n",
        "\n",
        "코딩 스타일에 맞춰 원하시는 api를 선택하셔서 사용하시면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TQe1Nw8QLMu",
        "outputId": "c06e79c9-fe98-433d-cebe-43661807583c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "loss = loss_fn(z, y)\n",
        "loss"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6197, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gihsaH3ULCRN",
        "outputId": "23ac4b10-331f-4efb-efc8-fce619a63df0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
        "loss"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6197, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCsd5yep3-sj"
      },
      "source": [
        "## Backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfNejCDye61c"
      },
      "source": [
        "모델에서 매개변수의 가중치를 최적화하려면 파라미터에 대한 loss function의 도함수(derivative)를 계산해야 합니다. \n",
        "이러한 도함수를 계산하기 위해, loss.backward() 를 호출한 다음 w.grad와 b.grad에서 값을 가져옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptZdnLSu5vC",
        "outputId": "9f299301-b698-4fe4-b732-65e59469a499",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss.backward()\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[0.0155, 0.2621, 0.0784],\n",
            "        [0.0155, 0.2621, 0.0784],\n",
            "        [0.0155, 0.2621, 0.0784],\n",
            "        [0.0155, 0.2621, 0.0784],\n",
            "        [0.0155, 0.2621, 0.0784]])\n",
            "tensor([0.0155, 0.2621, 0.0784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFE4lc-lfYtf"
      },
      "source": [
        "기본적으로, requires_grad=True인 모든 텐서들은 연산 기록을 추적하고 미분 계산을 지원합니다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 forward 연산만 필요한 경우에는, 미분 연산을 위한 값들을 저장해두는 것이 속력 및 메모리의 저하를 가져올 수 있습니다. 연산 코드를 torch.no_grad() 블록으로 둘러싸서 미분 추적을 멈출 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaiqxruWT_so",
        "outputId": "ac663f32-9d0d-4876-8b38-78b1472bacb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NqQRDaKqU6"
      },
      "source": [
        "# Reference\n",
        "\n",
        "1. https://tutorials.pytorch.kr/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6uX96q05Ddha"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}
